{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pdfminer.pdfpage import PDFPage - Python2\n",
    "\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument, PDFNoOutlines\n",
    "from pdfminer.converter import PDFPageAggregator, TextConverter#, XMLConverter, HTMLConverter\n",
    "\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine #, LTFigure, LTImage\n",
    "\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we only want to keep English. The functions below identify the probabilities of a text being written in a given language (using stop words). The language is takes as the max in languages_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_languages(text):\n",
    "    '''\n",
    "    nltk.wordpunct_tokenize() splits all punctuations into separate tokens\n",
    "    \n",
    "    >>> wordpunct_tokenize(\"My name's Anna.End.\")\n",
    "    ['My', name', 's', 'Anna', '.', 'End', '.']\n",
    "    '''\n",
    "    languages_ratios = {}\n",
    "\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    words = [word.lower() for word in tokens]\n",
    "\n",
    "    # number of unique stopwords appearing in analyzed text as included in nltk(Africaans classified as Dutch)\n",
    "    for language in stopwords.fileids():\n",
    "        stopwords_set = set(stopwords.words(language))\n",
    "        words_set = set(words)\n",
    "        common_elements = words_set.intersection(stopwords_set)\n",
    "\n",
    "        languages_ratios[language] = len(common_elements) # language \"score\"\n",
    "\n",
    "    return languages_ratios\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "def detect_language(text):\n",
    "    \"\"\"\n",
    "    Calculate probability of given text to be written in a given language,\n",
    "    returning the highest score and ratios\n",
    "    \"\"\"\n",
    "\n",
    "    ratios = get_languages(text)\n",
    "    \n",
    "    most_rated_language = max(ratios, key=ratios.get)\n",
    "\n",
    "    return most_rated_language, ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_parsed=[]\n",
    "\n",
    "fp = open('3489_31-8_ECape.pdf', 'rb') # from a local file\n",
    "parser = PDFParser(fp)\n",
    "        \n",
    "doc = PDFDocument()\n",
    "parser.set_document(doc)\n",
    "doc.set_parser(parser)\n",
    "doc.initialize('')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        # Process each page contained in the document.\n",
    "        \n",
    "for page in doc.get_pages():\n",
    "            interpreter.process_page(page)\n",
    "            \n",
    "            # layout analyzer: an LTPage object for each page in the PDF document.\n",
    "            #This object contains child objects within the page, forming a tree structure\n",
    "            layout = device.get_result()\n",
    "            \n",
    "            \n",
    "            for lt_obj in layout:\n",
    "            #Represents a group of text chunks that can be contained \n",
    "            #in a rectangular area. Created by geometric analysis, not necessarily \n",
    "            #represents a logical boundary of the text. It contains a list of\n",
    "            #LTTextLine objects: Contains a list of LTChar objects that represent \n",
    "            #a single text line. The characters are aligned either horizontaly\n",
    "            #or vertically, \n",
    "            #get_text() method returns the text content. \n",
    "                if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "                        text_obj = lt_obj.get_text().replace('\\n','')\n",
    "                        language, ratios = detect_language(text_obj)\n",
    "                        if (language==\"english\" and not(text_obj in text_parsed)):\n",
    "                            #(\\d{1,2} )?(Nov|Dec)?( ?- )?(\\d{1,2}) (Nov|Dec) (\\d{4}) \n",
    "                                text_parsed.append(text_obj)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial pipeline\n",
    "\n",
    "### 1. information about a given gazette is in the first page (vol, no, type etc)\n",
    "\n",
    "### 2. we look for places in the doc (page no), where of the most relevant content, so (for now) parsing the 'outline' \n",
    "\n",
    "After reading the 1st page, we look for a page containing an 'outline' of sorts.\n",
    "\n",
    "This is a major hack, as accessing the table of contents (\"Outlines\") does not work for the gazettes (they are boxes)\n",
    "http://www.unixuser.org/~euske/python/pdfminer/programming.html#layout\n",
    "\n",
    "We identify the page by containing a variation of the following:\n",
    "\n",
    "GENERAL NOTICE / ALGEMENE KENNISGEWINGS\n",
    "CONTENT/Table of contents (actually is Table of ConTenTs, so need to switch to small fonts)\n",
    "\n",
    "difficulties:\n",
    "- page number in outline might not be a separate box (while in the same doc others are)\n",
    "- page no. might appear at the end: 'table of contents' + entries + page no header\n",
    "\n",
    "not sure if it's the pdf or pdfminer's fault\n",
    "\n",
    "Idea in the long run:\n",
    "extend the PDFPageInterpreter and PDFDevice class in order to process them differently / obtain other information. \n",
    "\n",
    "### 3. going to the indentified page and if it's in English, extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_first_page(objstack_t):\n",
    "    first_text = []\n",
    "    while objstack_t:\n",
    "            lt_obj=objstack_t.pop()\n",
    "            \n",
    "            if isinstance(lt_obj, LTTextBox): #or isinstance(lt_obj, LTTextLine):\n",
    "                    text_obj = lt_obj.get_text().replace('\\n','')\n",
    "                        \n",
    "                        #language, ratios = detect_language(text_obj)\n",
    "                    if ('Registered' not in text_obj):\n",
    "                        \n",
    "                        first_text.append(text_obj)\n",
    "                        \n",
    "                        if ('No.' in text_obj):\n",
    "                          #if not(text_obj in text_parsed) and ('GENERAL NOTICE' in text_obj):\n",
    "                        \n",
    "                          break\n",
    "                       \n",
    "    return first_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_outline(objstack):\n",
    "        text_obj=[]\n",
    "        start = 0 # beg of the outline\n",
    "        outline_obj = []\n",
    "        is_outline_page = 0\n",
    "        page_box = []\n",
    "        gazette_box = []\n",
    "        \n",
    "        while objstack:\n",
    "            lt_obj=objstack.pop()\n",
    "            \n",
    "            if isinstance(lt_obj, LTTextBox): #or isinstance(lt_obj, LTTextLine):\n",
    "                        text_obj = lt_obj.get_text().replace('\\n',' ').lower()\n",
    "                        \n",
    "                        #parse all below 'content':\n",
    "                        if ('contents' in text_obj) or ('provincial notices' in text_obj)\\\n",
    "                           or ('page no' in text_obj) or ('gazette no' in text_obj):\n",
    "                                #print(\"contents\", lt_obj)\n",
    "                                start = 1\n",
    "                                is_outline_page = 1\n",
    "                        #print(start, text_obj)        \n",
    "                        if (start==1):\n",
    "                           \n",
    "                            if ('page' in text_obj):\n",
    "                                page_box = lt_obj\n",
    "                                #print(text_obj)\n",
    "                                #print(page_box)\n",
    "                            if ('gazette no' in text_obj):\n",
    "                                gazette_box = lt_obj\n",
    "                                \n",
    "                            outline_obj.append(lt_obj) \n",
    "                            \n",
    "                \n",
    "        return is_outline_page, outline_obj, page_box, gazette_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open the pdf file\n",
    "fp = open('39782_4-3_NationalLiquor.pdf', 'rb')\n",
    "parser = PDFParser(fp)\n",
    "doc = PDFDocument()\n",
    "parser.set_document(doc)\n",
    "doc.set_parser(parser)\n",
    "doc.initialize() # optional if passwo is there: pdf_pwd\n",
    "\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "# to use in-built pdftotxt.py:\n",
    "#device = TextConverter(rsrcmgr, outfp, laparams=LAParams()) \n",
    "#process_pdf(rsrcmgr, device, fp) \n",
    "#device.close() \n",
    "\n",
    "text_parsed = [] # a list of strings, each representing text collected from each page of the doc\n",
    "\n",
    "# find the number of pages- starts from 0\n",
    "num_pages = max([i for i,page in enumerate(doc.get_pages())])\n",
    "\n",
    "\n",
    "# find page with content (not defined as outline in the doc, unfortnately)\n",
    "for i, page in enumerate(doc.get_pages()):\n",
    "    try:\n",
    "           interpreter.process_page(page)\n",
    "    except Exception as e:\n",
    "            print(\"parsing of the first page is not possible\")\n",
    "            continue\n",
    "    # receive the LTPage object for this page\n",
    "    #The layout received from get_result() parses the strings into separate objects. \n",
    "    #These objects have several key components:type, the coordinates \n",
    "    #(startingx, startingy, endingx, endingy), and the content, e.g.\n",
    "    #<LTRect 258.000,39.720,297.000,51.000>\n",
    "    #Accessing the type sone by type(object)(e.g. type(object)==LTRect). \n",
    "    layout = device.get_result()\n",
    "            \n",
    "    objstack=list(reversed(layout._objs))\n",
    "        \n",
    "    # get the first page info: type of gazette, vol and data\n",
    "    if i==0:\n",
    "        \n",
    "        first_text = get_first_page(objstack)\n",
    "        # extract specific info: vol, date, place, type of gazzette\n",
    "        #.....\n",
    "        \n",
    "    else:\n",
    "        # find page with the outline and extract outline text and pages it points to:\n",
    "        is_outline_page, outline_obj, page_box, gazette_box = get_outline(objstack)\n",
    "        if (is_outline_page):\n",
    "            #print(is_outline_page, i)\n",
    "            num_outline_page=i\n",
    "            break # we found the outline so move to extracting pages from there\n",
    "\n",
    "#now we have to fetch the columns corresponding to the 'page no' or 'page' \n",
    "#and extract the page numbers the main info is stored at\n",
    "\n",
    "           \n",
    "fp.close()\n",
    "device.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = page_box.x0\n",
    "x1 = page_box.x1\n",
    "\n",
    "# page numbers can be misaligned-> 'Gazette no.' column overlaps \n",
    "# in the heading with the column of Page numbers. What that means is that\n",
    "# we cannot use coordinates of boxes to fetch 'Page no'. \n",
    "# In practial terms: the 'Page no' x1 coordinate needs to be extended to 'Gazette no' x0\n",
    "\n",
    "if gazette_box != []:\n",
    "    g_x0 = gazette_box.x0 \n",
    "else:\n",
    "    g_x0 = x1\n",
    "    \n",
    "page_contents = []\n",
    "for box in outline_obj:\n",
    "    text_obj = box.get_text().replace('\\n',' ').lower()\n",
    "    if (box.x0 >= x0 and box.x1 <= x1) or (box.x0 >= x0 and box.x1 < g_x0):\n",
    "\n",
    "        if not ('page' in text_obj):\n",
    "            if (len(text_obj)>1): # sometimes pages come as a vector, so we split the elements\n",
    "                temp = text_obj.split(' ')\n",
    "                for l in temp:\n",
    "                    if len(l)>0:\n",
    "                        page_contents.append(int(float(l)))     \n",
    "\n",
    "            else:     \n",
    "                page_contents.append(int(text_obj))\n",
    "            \n",
    "    if ('..' in text_obj):\n",
    "        t = text_obj.split('.')\n",
    "        last_el = t[-1].strip()\n",
    "        print(last_el)\n",
    "        if last_el != '':\n",
    "            x = int(float(last_el))\n",
    "            \n",
    "            if (x<=(num_pages+1)):  # sometimes gazette number parses in\n",
    "               \n",
    "                page_contents.append(x)\n",
    "#unique pages\n",
    "pages_to_extract = list(set(page_contents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 42, 43, 44, 21]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_to_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 'pages to extract' we can\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "totally unstructured (to say the least):\n",
    " Extraordinary Provincial Gazette of KwaZulu-Natal\n",
    " 1156_9-6_KznG1.pdf\n",
    "\n",
    "KznElec: ELECTION TIMETABLE, outline: ok\n",
    "KznSep: MUNICIPAL/Provincial NOTICE, outline: ok\n",
    "KznDemarc: outline:ok, BUT it refers only to general changes, followed by unreferenced pages with data on ward changes. This data, however, can be accessed from other source (registered \n",
    "voters in each wards etc).\n",
    "\n",
    "NCape:\n",
    "Liquor: ok\n",
    "\n",
    "Gauteng:\n",
    "outline: single vector pages split by municipalities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
